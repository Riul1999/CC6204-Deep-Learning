{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea1_RU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCszeuRk0NuH"
      },
      "source": [
        "# Tarea 1: Activaciones y pasada hacia adelante en una red neuronal <br/> CC6204 Deep Learning, Universidad de Chile  <br/> Hoja de respuestas\n",
        "## Nombre: \n",
        "Fecha de entrega: 2 de octubre de *2020*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QQB7jV7LMEo",
        "outputId": "c96fa5aa-0396-4c1a-d853-88b9c5bd708b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "# Este notebook está pensado para correr en CoLaboratory. \n",
        "# Lo único imprescindible por importar es torch \n",
        "import torch\n",
        "\n",
        "# Posiblemenete quieras instalar e importar ipdb para debuggear.\n",
        "# Si es así, descomenta lo siguiente\n",
        "# !pip install -q ipdb\n",
        "# import ipdb\n",
        "\n",
        "# Aqui instalamos la libreria de correccion del curso\n",
        "!pip install \"git+https://github.com/dccuchile/CC6204.git@master#egg=cc6204&subdirectory=autocorrect\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cc6204\n",
            "  Cloning https://github.com/dccuchile/CC6204.git (to revision master) to /tmp/pip-install-yvcu1w2z/cc6204\n",
            "  Running command git clone -q https://github.com/dccuchile/CC6204.git /tmp/pip-install-yvcu1w2z/cc6204\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from cc6204) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cc6204) (1.18.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from cc6204) (1.6.0+cu101)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->cc6204) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->cc6204) (0.16.0)\n",
            "Building wheels for collected packages: cc6204\n",
            "  Building wheel for cc6204 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cc6204: filename=cc6204-0.2.2-cp36-none-any.whl size=4674 sha256=04010fee3060a6dcfab6775428ec35e1d01a067b425f5b97e88f3c4ae6837b7f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ws953bp3/wheels/62/f0/30/aadcb7ce24a2f9c935890518e902d4e23bf97b80f47bb64414\n",
            "Successfully built cc6204\n",
            "Installing collected packages: cc6204\n",
            "Successfully installed cc6204-0.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49OevYJkMdgW",
        "outputId": "d7296c4b-4100-43e6-f2dd-d3c6088e2cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# importamos las herramientas del curso\n",
        "from cc6204 import AutoCorrect, FailedTest\n",
        "\n",
        "# ingresa el host y port que posteamos en u-cursos\n",
        "\n",
        "corrector = AutoCorrect(host=\"cc6204.dcc.uchile.cl\", port=443)\n",
        "\n",
        "# anota el token que te daremos en u-cursos\n",
        "\n",
        "token = \"]ye/Ox;nsz\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Connection stablished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq9u0IfT0VRp"
      },
      "source": [
        "# Parte 1: Funciones de activación y función de salida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMw80P8o0qrJ"
      },
      "source": [
        "## 1a) Funciones de activación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDhcNbNT0YNr"
      },
      "source": [
        "def sig(T):\n",
        "  return torch.reciprocal(1 + torch.exp(-1 * T))\n",
        "\n",
        "def tanh(T):\n",
        "  E = torch.exp(T)\n",
        "  e = torch.exp(-1 * T)\n",
        "  return (E - e) * torch.reciprocal(E + e)\n",
        "\n",
        "# Tu código acá\n",
        "def relu(T):\n",
        "  zeros=T*0                 #construmimos arreglo auxiliar usando T para que esten en el mismo device\n",
        "  return torch.max(T,zeros) #se devuelve el maximo entre T y 0, esto lo hace componente a componente por lo que hace lo pedido\n",
        "\n",
        "def swish(T, beta ):\n",
        "  return torch.mul(T,sig(T*beta)) #se multiplica componente a componente T con sigmoid(T*beta) que es lo que hace swish\n",
        "\n",
        "def celu(T, alfa):\n",
        "  pos= (T>=0)*1 #se crea un arreglo con unos donde la componente de T es mayor o igual que 0, cero en todo el resto\n",
        "  neg= (T<0)*1 #se crea un arreglo con unos donde la componente de T es menor a 0, cero en todo el resto\n",
        "  return torch.add(torch.mul(T,pos),torch.mul(alfa*(torch.sub(torch.exp(T/alfa),1)),neg))\n",
        "  #usando los arreglo neg y pos se logra ver que componentes de T deben mostrar T (donde T es >=0) y donde deben mostrar \n",
        "  #alfa*exp((T/alfa)-1) (donde T es <0)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0SmO2x7M1pn",
        "outputId": "a6724b13-b572-4102-b898-0f0f81157dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# correccion\n",
        "test_relu = corrector.get_test_data(homework=1, question=\"1a\", test=1, token=token)\n",
        "test_swish, swish_par = corrector.get_test_data(homework=1, question=\"1a\", test=2, token=token)\n",
        "test_celu, celu_par = corrector.get_test_data(homework=1, question=\"1a\", test=3, token=token)\n",
        "#test se pasan de listas a tensores\n",
        "test_relu = torch.tensor(test_relu)\n",
        "test_swish = torch.tensor(test_swish)\n",
        "test_celu = torch.tensor(test_celu)\n",
        "\n",
        "corrector.sumbit(homework=1, question=\"1a\", test=1, token=token, answer=relu(test_relu))\n",
        "corrector.sumbit(homework=1, question=\"1a\", test=2, token=token, answer=swish(test_swish, swish_par))\n",
        "corrector.sumbit(homework=1, question=\"1a\", test=3, token=token, answer=celu(test_celu, celu_par))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cached test data\n",
            "Using cached test data\n",
            "Using cached test data\n",
            "Correct Test!\n",
            "Correct Test!\n",
            "Correct Test!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_0dTh7l1bas"
      },
      "source": [
        "## 1b) Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjIyp2nL1le5"
      },
      "source": [
        "**Demostracion:**\n",
        "\n",
        "Sea $X$=($x_{1}$,$x_{2}$,...,$x_{n}$), $X^{'}$=($x_{1}-M$,$x_{2}-M$,...,$x_{n}-M$), entonces:\n",
        "\n",
        "softmax($X$)=($s_{1}$,$s_{2}$,...,$s_{n}$), donde $s_{i}$=$\\frac{e^{x_{i}}}{\\sum_{j=1}^{n}e^{x_{j}}}$, con $i=1,...,n$\n",
        "\n",
        "Luego, softmax($X^{'}$)=($s_{1}^{'}$,$s_{2}^{'}$,...,$s_{n}^{'}$), donde $s_{i}^{´}$=$\\frac{e^{x_{i}-M}}{\\sum_{j=1}^{n}e^{x_{j}-M}}$, \n",
        "\n",
        "pero $e^{x_{i}-M}$ = $e^{x_{i}}*e^{-M}$ y tambien ${\\sum_{j=1}^{n}e^{x_{j}-M}}$ =${\\sum_{j=1}^{n}e^{x_{i}}*e^{-M}$=$e^{-M}*\\sum_{j=1}^{n}e^{x_{j}}}$\n",
        "\n",
        "Por lo tanto  $s_{i}^{´}$=$\\frac{e^{x_{i}-M}}{\\sum_{j=1}^{n}e^{x_{j}-M}}$ = $\\frac{e^{-M}*e^{x_{i}}}{e^{-M}*\\sum_{j=1}^{n}e^{x_{j}}}$=$\\frac{e^{x_{i}}}{\\sum_{j=1}^{n}e^{x_{j}}}$=$s_{i}$, esto para todo $i=1,...,n$.\n",
        "\n",
        "Con lo cual, se llega a que sorfmax($X^{'}$)=softmax($X$)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDg2sU7D1dIY"
      },
      "source": [
        "# Tu código acá\n",
        "\n",
        "def softmax(T, dim, estable=True):\n",
        "  if estable:                                #esto es que queremos restar el mismo valor por cada componente de la dimension dim\n",
        "    aux=torch.max(T,dim=dim,keepdim=True)[0] #aqui construimos un arreglo auxiliar con las \"mismas dimensiones\" que T \n",
        "    aux=torch.exp(torch.sub(T,aux))          #(tiene un 1 en la dimension dim) y guarda los maximos por componente en esa dimension de T\n",
        "                                             #luego se le resta ese maximo a cada componente (siempre a la correspondiente) y saca exp\n",
        "  else:                                      #estable=false, por lo que no restamos nada\n",
        "    aux=torch.exp(T)                         #solo tomamos exp\n",
        "  return torch.div(aux,torch.sum(aux,dim,keepdim=True))  #devolvemos la division entre la componente y la suma en dicha dimension"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nJhjuGZXgkM",
        "outputId": "0b56c82b-80f2-4043-f27e-28d09dda2cbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_softmax, _dim = corrector.get_test_data(homework=1, question=\"1b\", test=1, token=token)\n",
        "test_softmax = torch.tensor(test_softmax)\n",
        "corrector.sumbit(homework=1, question=\"1b\", test=1, token=token, answer=softmax(test_softmax, dim=_dim))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cached test data\n",
            "Correct Test!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "662XLsDA9XXI"
      },
      "source": [
        "# Parte 2: Red neuronal y pasada hacia adelante (forward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTUm9ZbX9bRA"
      },
      "source": [
        "## 2a) Clase para red neuronal, 2b) Iterando por parametros, 2d) Pasada hacia adelante"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_jeuYbv9WhK"
      },
      "source": [
        "# Tu código debiera continuar así \n",
        "\n",
        "class FFNN(torch.nn.Module):\n",
        "  def __init__(self, F, l_h, l_a, C):\n",
        "    super(FFNN, self).__init__()\n",
        "    #pasamos todos los parametros a torch.nn.Parameter(), y definimos las variables de los parametros (pesos) y los sesgos de la red\n",
        "    self.F=torch.nn.Parameter(torch.Tensor([F]))\n",
        "    self.l_h=torch.nn.Parameter(torch.Tensor(l_h))\n",
        "    self.l_a=l_a\n",
        "    self.C=torch.nn.Parameter(torch.Tensor([C]))\n",
        "    self.parametros=None\n",
        "    self.sesgos=None\n",
        "  \n",
        "  def setParameters(self,W,b,U,c):\n",
        "    #incializamos o modificamos los parametros y sesgos de la red, juntamos W con U y b con c\n",
        "    self.parametros=torch.nn.ParameterList([torch.nn.Parameter(W[i]) for i in range(len(W))]+[torch.nn.Parameter(U)])\n",
        "    self.sesgos=torch.nn.ParameterList([torch.nn.Parameter(b[i]) for i in range(len(b))]+[torch.nn.Parameter(c)])\n",
        "\n",
        "  def resumen(self):\n",
        "    # Usa self.named_parameters(). y retorna todos los parametros reconocidos de la neurona\n",
        "    for param in self.named_parameters():\n",
        "      print(param)\n",
        "      pass\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # Usa los parámetros y funciones de activación.\n",
        "    # Retorna y = softmax(capa_de_salida).\n",
        "    h=self.l_a[0](torch.add(torch.mm(x,self.parametros[0]),self.sesgos[0]))     #inicializamos h con (la primera multiplicacion entre x y W1) + b1\n",
        "    for i in range(1,len(self.sesgos)-1):                                       #recorremos todos los parametros (todas las matrices de peso), excepto la ultima\n",
        "      h=self.l_a[i](torch.add(torch.mm(h,self.parametros[i]),self.sesgos[i]))   #redefinimos h como vimos en clases\n",
        "    return softmax(torch.add(torch.mm(h,self.parametros[-1]),self.sesgos[-1]),1)#devolvemos softmax de los predicho por nuestra red (y)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgf5Xx-34Pa1"
      },
      "source": [
        "## 2c) Moviendo los parámetros entre dispositivos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zppplXd4QXa",
        "outputId": "853f35ce-ab59-48a3-c469-380b8bd71ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        }
      },
      "source": [
        "#Probamos que nuestros parametros esten bien definidos en nuestra red, al no inicializar los parametros y los sesgos no se consume mucha ram\n",
        "redes_neuronales= FFNN(100000,[5000,3000,4000,20000],[relu,sig,relu,relu],100)\n",
        "torch.cuda.empty_cache() \n",
        "!nvidia-smi\n",
        "redes_neuronales.cuda()\n",
        "!nvidia-smi"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Sep 27 22:39:35 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    28W /  70W |    899MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Sun Sep 27 22:39:35 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    28W /  70W |    899MiB / 15079MiB |      1%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTnKxznL6Ep"
      },
      "source": [
        "# Parte 3: Probando tu red con parámetros pre-entrenados para MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOBcElJ7BPcQ",
        "outputId": "9b39e55d-bbc0-4987-fa1a-a2bae91a9920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from matplotlib.pyplot import subplots\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "\n",
        "# Descarga y almacena el conjunto de prueba de MNIST.\n",
        "dataset = MNIST('mnist', train=False, transform=ToTensor(), download=True)\n",
        "print('Cantidad total de datos:',len(dataset))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad total de datos: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6s-z1DNL-J0"
      },
      "source": [
        "## 3b) Cargando los parámetros pre-entrenados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLeq3y8FE3SU"
      },
      "source": [
        "#descargamos los parametros y sesgos ya entrenados\n",
        "!wget -O U.txt https://raw.githubusercontent.com/dccuchile/CC6204/master/2020/tareas/tarea1/mnist_weights/U.txt\n",
        "!wget -O W1.txt https://raw.githubusercontent.com/dccuchile/CC6204/master/2020/tareas/tarea1/mnist_weights/W1.txt\n",
        "!wget -O W2.txt https://raw.githubusercontent.com/dccuchile/CC6204/master/2020/tareas/tarea1/mnist_weights/W2.txt\n",
        "!wget -O b1.txt https://raw.githubusercontent.com/dccuchile/CC6204/master/2020/tareas/tarea1/mnist_weights/b1.txt\n",
        "!wget -O b2.txt https://raw.githubusercontent.com/dccuchile/CC6204/master/2020/tareas/tarea1/mnist_weights/b2.txt\n",
        "!wget -O c.txt https://raw.githubusercontent.com/dccuchile/CC6204/master/2020/tareas/tarea1/mnist_weights/c.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzNdFAjNU0IW"
      },
      "source": [
        "from numpy import loadtxt\n",
        "#guardamos los parametros en variables para poder utilizarlos\n",
        "U = torch.from_numpy(loadtxt('U.txt')).float()\n",
        "W1 = torch.from_numpy(loadtxt('W1.txt')).float()\n",
        "W2 = torch.from_numpy(loadtxt('W2.txt')).float()\n",
        "b1 = torch.from_numpy(loadtxt('b1.txt')).float()\n",
        "b2 = torch.from_numpy(loadtxt('b2.txt')).float()\n",
        "c = torch.from_numpy(loadtxt('c.txt')).float()"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuyBy1e3XO6E"
      },
      "source": [
        "#creamos nuestra red neuronal con la arquitectura dicha en el enunciado\n",
        "red_neuronal=FFNN(784,[32,16],[relu,relu],10)\n",
        "#cargamos los parametros y sesgos ya entrenados a la red\n",
        "red_neuronal.setParameters([W1,W2],[b1,b2],U,c)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWRa68ZFMIyr"
      },
      "source": [
        "## 3c) Cálcula la predicción de un ejemplo al azar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-SaIzRoMMoc",
        "outputId": "31769132-f81f-4b53-93ce-2390af94a52a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import random\n",
        "index = random.randint(0,len(dataset))               #obtenemos imagen al azar del dataset\n",
        "T, l = dataset[index]                                #guardamos el vector de features (T) y su categoria (l)\n",
        "numero = T.view(28,28).numpy()                       #modificamos la imagen para plotearla mas facil\n",
        "fig1 = plt.imshow(numero)                            #plot de la imagen\n",
        "plt.title(\"clase: \"+ str(l))                         #titulo de la imagen\n",
        "plt.show()\n",
        "print(red_neuronal.forward(T.view(1,784)).argmax(1)) #printeamos el resultado predicho por nuestra red (aveces se equivoca)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1cZFU8rMNr1"
      },
      "source": [
        "## 3d) Pasando todos los ejemplos por la red con un `DataLoader`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL49_0ZAMRd_"
      },
      "source": [
        "# Acá tu código\n",
        "from torch.utils.data import DataLoader\n",
        "def calcula_acierto(red, dataset, batch_size=100, device='cuda'):\n",
        "  dataloader=DataLoader(dataset,batch_size)                           #cargamos los datos en paquetes\n",
        "  aciertos=0                                                          #incializamos lo que devolveremos\n",
        "  red=red.to(device)                                                  #pasamos toda la red al device ingresado\n",
        "  for x,y in dataloader:                                              #recorremos por paquetes nuestro dataset\n",
        "    x=x.to(device)                                                    #pasamos x al device ingresado\n",
        "    y=y.to(device)                                                    #pasamos y al device ingresado\n",
        "    y_gorro=red.forward(x.view(batch_size,-1)).argmax(1)              #modificamos x para que calce en nuestra red y guardamos la prediccion\n",
        "    aciertos += ((torch.sum((y_gorro==y.view(batch_size))*1))).item() #guardamos el numero de aciertos\n",
        "  return aciertos/len(dataset)                                     #obtemos el porcentaje de aciertos dividiendo el obtenido por el total"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHv3C3giqJzw",
        "outputId": "260c2f3f-d149-4d83-cfc8-17f679c8b87d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(calcula_acierto(red_neuronal,dataset,10000,'cuda'))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZdAsq-WqS3O",
        "outputId": "da281863-5449-4daf-a2af-906868636397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(calcula_acierto(red_neuronal,dataset,10000,'cpu'))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKXqo4FpX2Id"
      },
      "source": [
        "### Correccion red"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itWs4t9feO1u",
        "outputId": "4fe9dc68-6f00-4418-ab07-26d2fce82b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from torch.utils.data import Subset\n",
        "indices = corrector.get_test_data(homework=1, question=\"network\", test=1, token=token)\n",
        "test_set = Subset(dataset, indices)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cached test data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMcid2LRXzrg",
        "outputId": "f01cbead-1e19-4198-cbaf-8e17713981ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "red = red_neuronal.to('cuda')                  #se define la red y se pasa a cuda\n",
        "dataloader=DataLoader(test_set,50)             #se carga el test_set en paquetes de 50 ejemplos (es solo 1)\n",
        "y_gorro=torch.Tensor([])                       #se inicializa el vector de prediccion\n",
        "for x,y in dataloader:                         #se hace for para generalizar y poder probar con otros datasets\n",
        "  x=x.to('cuda')                               #se pasa x a cuda\n",
        "  y_gorro=torch.cat((y_gorro,(red.forward(x.view(50,-1)).argmax(1).to('cpu')).view(50)),0) #se calcula prediccion y se juntan en un vector\n",
        "result = y_gorro                               #se guarda la prediccion en la variable result\n",
        "print(calcula_acierto(red,test_set,25,'cuda')) #se ve \"precision\" de la red para el test_set\n",
        "\n",
        "corrector.sumbit(homework=1, question=\"network\", test=1, token=token, answer=result)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "Correct Test!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pgWygWCMYTx"
      },
      "source": [
        "## 3e) Opcional: Muestra los casos en donde la red se equivoca"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM_eP23XMaTn"
      },
      "source": [
        "# Acá tu código"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beF870pABHKe"
      },
      "source": [
        "## 3d) Opcional: Crea tus propios ejemplos de dígitos para clasificar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOqCJx4LBG1W"
      },
      "source": [
        "# Acá tu código"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}